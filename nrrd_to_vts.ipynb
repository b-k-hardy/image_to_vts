{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7396ce",
   "metadata": {},
   "source": [
    "# Python Notebook to Figure Out .vts Files\n",
    "\n",
    "Brandon Hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc07be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import nrrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa30f3",
   "metadata": {},
   "source": [
    "## Putting MR Angiography Images in Correct Coordinate System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f9c6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NRRD file\n",
    "filename = \"test/603 MRA Last Phase.nrrd\"\n",
    "data, header = nrrd.read(filename)\n",
    "\n",
    "# Extract space dimensions\n",
    "space_dimensions_MRA = header['space directions'].T\n",
    "space_origin = header['space origin']\n",
    "data_size = header['sizes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6317d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start with a meshgrid where each position in the meshgrid has an integer value (0, 1, 2, ...), since\n",
    "# the nrrd header specifies how space changes as we increment the unit\n",
    "# vectors by 1. I'm not sure if this is how other headers operate (nifti, DICOM),\n",
    "# but this works for nrrd files\n",
    "\n",
    "xv = np.arange(0, data_size[0] + 1, dtype=np.float32) # add 1 because we need point locations for pyvista\n",
    "yv = np.arange(0, data_size[1] + 1, dtype=np.float32)\n",
    "zv = np.arange(0, data_size[2] + 1, dtype=np.float32)\n",
    "\n",
    "X, Y, Z = np.meshgrid(xv, yv, zv, indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f59d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ravel to 1D and transform all coordinates at once\n",
    "coords = np.vstack((X.ravel(), Y.ravel(), Z.ravel()))\n",
    "transformed_coords = np.dot(space_dimensions_MRA, coords) + space_origin[:, np.newaxis]\n",
    "\n",
    "X = transformed_coords[0, :].reshape(X.shape)\n",
    "Y = transformed_coords[1, :].reshape(Y.shape)\n",
    "Z = transformed_coords[2, :].reshape(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c40c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert coordinates to float32 to save space\n",
    "X = np.asarray(X, dtype=np.float32)\n",
    "Y = np.asarray(Y, dtype=np.float32)\n",
    "Z = np.asarray(Z, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fad71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pv.StructuredGrid(X, Y, Z)\n",
    "grid.cell_data[\"Image Intensity\"] = data.flatten(order=\"F\")\n",
    "grid.field_data[\"Space Origin\"] = space_origin\n",
    "plane_normals = np.linalg.inv(space_dimensions_MRA)\n",
    "grid.field_data[\"Image Axis 1\"] = plane_normals[0] # I don't really know why I'm inverting this but it gives the right result if you want to draw planes along the axial, saggital, and coronal planes\n",
    "grid.field_data[\"Image Axis 2\"] = plane_normals[1]\n",
    "grid.field_data[\"Image Axis 3\"] = plane_normals[2]\n",
    "grid.save(\"603_MRA_Last_Phase.vts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba957af2",
   "metadata": {},
   "source": [
    "## Putting 4D Flow Images in Correct Coordinate System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3837b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths and read in 4D flow data and segmentation masks\n",
    "phase_directions = [\"RL\", \"AP\", \"FH\"]\n",
    "paths = [f\"test/{direction}_4D/{903+i} MR DelRec - 4D PC_{direction} - 24 frames Volume Sequence by TriggerTime\" for i, direction in enumerate(phase_directions)]\n",
    "\n",
    "flow_header = nrrd.read_header(paths[0] + \" 0.nrrd\")\n",
    "space_dimensions_4Dflow = flow_header['space directions'].T\n",
    "space_origin = flow_header['space origin']\n",
    "data_size = flow_header['sizes']\n",
    "\n",
    "mask_TL = nrrd.read(\"test/Segmentation_TL_4DFLOWspace.nrrd\")[0]\n",
    "mask_FL = nrrd.read(\"test/Segmentation_FL_4DFLOWspace.nrrd\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b04d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xv = np.arange(0, data_size[0] + 1, dtype=np.float32)\n",
    "yv = np.arange(0, data_size[1] + 1, dtype=np.float32)\n",
    "zv = np.arange(0, data_size[2] + 1, dtype=np.float32) # plus 1 because we need point locations\n",
    "\n",
    "X, Y, Z = np.meshgrid(xv, yv, zv, indexing='ij')\n",
    "\n",
    "# ravel to 1D and transform all coordinates at once\n",
    "coords = np.vstack((X.ravel(), Y.ravel(), Z.ravel()))\n",
    "transformed_coords = np.dot(space_dimensions_4Dflow, coords) + space_origin[:, np.newaxis]\n",
    "\n",
    "X = transformed_coords[0, :].reshape(X.shape)\n",
    "Y = transformed_coords[1, :].reshape(Y.shape)\n",
    "Z = transformed_coords[2, :].reshape(Z.shape)\n",
    "\n",
    "X = np.asarray(X, dtype=np.float32)\n",
    "Y = np.asarray(Y, dtype=np.float32)\n",
    "Z = np.asarray(Z, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d02560b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from a function in a different set of code\n",
    "def import_flow(\n",
    "    paths: tuple[str, str, str],\n",
    "    timestep: float,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    vels = []\n",
    "    \n",
    "    for i, path in enumerate(paths):\n",
    "        # read in the nrrd file\n",
    "        data = nrrd.read(f\"{path} {timestep}.nrrd\")[0]\n",
    "        data[data < -199] = 0  # set weird cropped values to 0\n",
    "        data = data/100 # convert to m/s\n",
    "        \n",
    "        vels.append(data)\n",
    "        \n",
    "    return vels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b7fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 288, 40)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#paths[0] = paths_copy[2] # 0, 0, 1, 1, 2\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#paths[1] = paths_copy[0] # 1, 2, 0, 2, 1\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#paths[2] = paths_copy[1] # 2, 1, 2, 0, 0\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m24\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     vel_t \u001b[38;5;241m=\u001b[39m \u001b[43mimport_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nt \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(vel_t[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m, in \u001b[0;36mimport_flow\u001b[0;34m(paths, timestep)\u001b[0m\n\u001b[1;32m      7\u001b[0m vels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(paths):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# read in the nrrd file\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnrrd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtimestep\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.nrrd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m     data[data \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m199\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# set weird cropped values to 0\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;66;03m# convert to m/s\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/nrrd/reader.py:526\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, custom_field_map, index_order)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    525\u001b[0m     header \u001b[38;5;241m=\u001b[39m read_header(fh, custom_field_map)\n\u001b[0;32m--> 526\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, header\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/nrrd/reader.py:443\u001b[0m, in \u001b[0;36mread_data\u001b[0;34m(header, fh, filename, index_order)\u001b[0m\n\u001b[1;32m    439\u001b[0m decompressed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Read all the remaining data from the file\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# Obtain the length of the compressed data since we will be using it repeatedly, more efficient\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m compressed_data \u001b[38;5;241m=\u001b[39m \u001b[43mfh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m compressed_data_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(compressed_data)\n\u001b[1;32m    445\u001b[0m start_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 24 frames of 4D flow data\n",
    "# normalize the columns since we aren't going to scale the velocity data -- just change the orientation\n",
    "space_dimensions_vel = np.zeros((3, 3), dtype=np.float32)\n",
    "space_dimensions_vel[:, 0] = space_dimensions_MRA[:, 0] / np.linalg.norm(space_dimensions_MRA[:,0])\n",
    "space_dimensions_vel[:, 1] = space_dimensions_MRA[:, 1] / np.linalg.norm(space_dimensions_MRA[:,1])\n",
    "space_dimensions_vel[:, 2] = space_dimensions_MRA[:, 2] / np.linalg.norm(space_dimensions_MRA[:,2])\n",
    "\n",
    "# absolutely no idea why the MRA space works for the velocity vectors but it does... probably a weird coincidence\n",
    "# anyway I'm taking norm of each column to turn the matrix into a rotation matrix -- no scaling\n",
    "\n",
    "paths_copy = paths.copy()\n",
    "#paths[0] = paths_copy[2] # 0, 0, 1, 1, 2\n",
    "#paths[1] = paths_copy[0] # 1, 2, 0, 2, 1\n",
    "#paths[2] = paths_copy[1] # 2, 1, 2, 0, 0\n",
    "for nt in range(24):\n",
    "    vel_t = import_flow(paths, nt)\n",
    "    if nt == 1:\n",
    "        print(vel_t[0].shape)\n",
    "\n",
    "    for i in range(3):\n",
    "        vel_t[i] = vel_t[i] * (mask_FL + mask_TL !=0)  # combine the masks\n",
    "        vel_t[i] = vel_t[i].flatten(order=\"F\")\n",
    "    \n",
    "    # can't use dimensions exactly... need to orthonormalize?\n",
    "    vels = np.vstack((vel_t[0], vel_t[1], vel_t[2]))\n",
    "    transformed_vels = np.dot(space_dimensions_vel, vels)\n",
    "    \n",
    "    grid = pv.StructuredGrid(X, Y, Z)\n",
    "    grid.cell_data.set_vectors(transformed_vels.T, \"Velocity\")  # Assign velocity vectors to point data\n",
    "    grid.save(f\"4DFlow_{nt:02d}.vts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRA conversion matrix: \n",
      "[[ 0.845658  0.520558  0.103086]\n",
      " [-0.524349  0.851501  0.001216]\n",
      " [-0.099594 -0.06295   0.868906]]\n",
      "\n",
      "4D flow conversion matrix: \n",
      "[[ 0.617612 -0.139777 -2.114147]\n",
      " [ 1.010257 -0.001649  1.310873]\n",
      " [-0.074686 -1.178177  0.248985]]\n"
     ]
    }
   ],
   "source": [
    "# Set numpy print options to suppress scientific notation\n",
    "with np.printoptions(suppress=True, precision=6):\n",
    "    print(f\"MRA conversion matrix: \\n{space_dimensions_MRA}\\n\")\n",
    "    print(f\"4D flow conversion matrix: \\n{space_dimensions_4Dflow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78afff1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 261, 400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d149967c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3317760,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel_t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc5760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
